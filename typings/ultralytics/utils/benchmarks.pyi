"""
This type stub file was generated by pyright.
"""

"""
Benchmark a YOLO model formats for speed and accuracy.

Usage:
    from ultralytics.utils.benchmarks import ProfileModels, benchmark
    ProfileModels(['yolo11n.yaml', 'yolov8s.yaml']).profile()
    benchmark(model='yolo11n.pt', imgsz=160)

Format                  | `format=argument`         | Model
---                     | ---                       | ---
PyTorch                 | -                         | yolo11n.pt
TorchScript             | `torchscript`             | yolo11n.torchscript
ONNX                    | `onnx`                    | yolo11n.onnx
OpenVINO                | `openvino`                | yolo11n_openvino_model/
TensorRT                | `engine`                  | yolo11n.engine
CoreML                  | `coreml`                  | yolo11n.mlpackage
TensorFlow SavedModel   | `saved_model`             | yolo11n_saved_model/
TensorFlow GraphDef     | `pb`                      | yolo11n.pb
TensorFlow Lite         | `tflite`                  | yolo11n.tflite
TensorFlow Edge TPU     | `edgetpu`                 | yolo11n_edgetpu.tflite
TensorFlow.js           | `tfjs`                    | yolo11n_web_model/
PaddlePaddle            | `paddle`                  | yolo11n_paddle_model/
MNN                     | `mnn`                     | yolo11n.mnn
NCNN                    | `ncnn`                    | yolo11n_ncnn_model/
RKNN                    | `rknn`                    | yolo11n_rknn_model/
"""
def benchmark(model=..., data=..., imgsz=..., half=..., int8=..., device=..., verbose=..., eps=..., format=...):
    """
    Benchmark a YOLO model across different formats for speed and accuracy.

    Args:
        model (str | Path): Path to the model file or directory.
        data (str | None): Dataset to evaluate on, inherited from TASK2DATA if not passed.
        imgsz (int): Image size for the benchmark.
        half (bool): Use half-precision for the model if True.
        int8 (bool): Use int8-precision for the model if True.
        device (str): Device to run the benchmark on, either 'cpu' or 'cuda'.
        verbose (bool | float): If True or a float, assert benchmarks pass with given metric.
        eps (float): Epsilon value for divide by zero prevention.
        format (str): Export format for benchmarking. If not supplied all formats are benchmarked.

    Returns:
        (pandas.DataFrame): A pandas DataFrame with benchmark results for each format, including file size, metric,
            and inference time.

    Examples:
        Benchmark a YOLO model with default settings:
        >>> from ultralytics.utils.benchmarks import benchmark
        >>> benchmark(model="yolo11n.pt", imgsz=640)
    """
    ...

class RF100Benchmark:
    """Benchmark YOLO model performance across various formats for speed and accuracy."""
    def __init__(self) -> None:
        """Initialize the RF100Benchmark class for benchmarking YOLO model performance across various formats."""
        ...
    
    def set_key(self, api_key): # -> None:
        """
        Set Roboflow API key for processing.

        Args:
            api_key (str): The API key.

        Examples:
            Set the Roboflow API key for accessing datasets:
            >>> benchmark = RF100Benchmark()
            >>> benchmark.set_key("your_roboflow_api_key")
        """
        ...
    
    def parse_dataset(self, ds_link_txt=...): # -> tuple[list[Any], list[Any]]:
        """
        Parse dataset links and download datasets.

        Args:
            ds_link_txt (str): Path to the file containing dataset links.

        Examples:
            >>> benchmark = RF100Benchmark()
            >>> benchmark.set_key("api_key")
            >>> benchmark.parse_dataset("datasets_links.txt")
        """
        ...
    
    @staticmethod
    def fix_yaml(path): # -> None:
        """
        Fixes the train and validation paths in a given YAML file.

        Args:
            path (str): Path to the YAML file to be fixed.

        Examples:
            >>> RF100Benchmark.fix_yaml("path/to/data.yaml")
        """
        ...
    
    def evaluate(self, yaml_path, val_log_file, eval_log_file, list_ind): # -> None:
        """
        Evaluate model performance on validation results.

        Args:
            yaml_path (str): Path to the YAML configuration file.
            val_log_file (str): Path to the validation log file.
            eval_log_file (str): Path to the evaluation log file.
            list_ind (int): Index of the current dataset in the list.

        Returns:
            (float): The mean average precision (mAP) value for the evaluated model.

        Examples:
            Evaluate a model on a specific dataset
            >>> benchmark = RF100Benchmark()
            >>> benchmark.evaluate("path/to/data.yaml", "path/to/val_log.txt", "path/to/eval_log.txt", 0)
        """
        ...
    


class ProfileModels:
    """
    ProfileModels class for profiling different models on ONNX and TensorRT.

    This class profiles the performance of different models, returning results such as model speed and FLOPs.

    Attributes:
        paths (List[str]): Paths of the models to profile.
        num_timed_runs (int): Number of timed runs for the profiling.
        num_warmup_runs (int): Number of warmup runs before profiling.
        min_time (float): Minimum number of seconds to profile for.
        imgsz (int): Image size used in the models.
        half (bool): Flag to indicate whether to use FP16 half-precision for TensorRT profiling.
        trt (bool): Flag to indicate whether to profile using TensorRT.
        device (torch.device): Device used for profiling.

    Methods:
        profile: Profiles the models and prints the result.

    Examples:
        Profile models and print results
        >>> from ultralytics.utils.benchmarks import ProfileModels
        >>> profiler = ProfileModels(["yolo11n.yaml", "yolov8s.yaml"], imgsz=640)
        >>> profiler.profile()
    """
    def __init__(self, paths: list, num_timed_runs=..., num_warmup_runs=..., min_time=..., imgsz=..., half=..., trt=..., device=...) -> None:
        """
        Initialize the ProfileModels class for profiling models.

        Args:
            paths (List[str]): List of paths of the models to be profiled.
            num_timed_runs (int): Number of timed runs for the profiling.
            num_warmup_runs (int): Number of warmup runs before the actual profiling starts.
            min_time (float): Minimum time in seconds for profiling a model.
            imgsz (int): Size of the image used during profiling.
            half (bool): Flag to indicate whether to use FP16 half-precision for TensorRT profiling.
            trt (bool): Flag to indicate whether to profile using TensorRT.
            device (torch.device | None): Device used for profiling. If None, it is determined automatically.

        Notes:
            FP16 'half' argument option removed for ONNX as slower on CPU than FP32.

        Examples:
            Initialize and profile models
            >>> from ultralytics.utils.benchmarks import ProfileModels
            >>> profiler = ProfileModels(["yolo11n.yaml", "yolov8s.yaml"], imgsz=640)
            >>> profiler.profile()
        """
        ...
    
    def profile(self): # -> list[Any] | None:
        """Profiles YOLO models for speed and accuracy across various formats including ONNX and TensorRT."""
        ...
    
    def get_files(self): # -> list[Path]:
        """Returns a list of paths for all relevant model files given by the user."""
        ...
    
    @staticmethod
    def get_onnx_model_info(onnx_file: str): # -> tuple[float, float, float, float]:
        """Extracts metadata from an ONNX model file including parameters, GFLOPs, and input shape."""
        ...
    
    @staticmethod
    def iterative_sigma_clipping(data, sigma=..., max_iters=...): # -> NDArray[Any]:
        """Applies iterative sigma clipping to data to remove outliers based on specified sigma and iteration count."""
        ...
    
    def profile_tensorrt_model(self, engine_file: str, eps: float = ...): # -> tuple[float, float] | tuple[floating[Any], floating[Any]]:
        """Profiles YOLO model performance with TensorRT, measuring average run time and standard deviation."""
        ...
    
    def profile_onnx_model(self, onnx_file: str, eps: float = ...): # -> tuple[floating[Any], floating[Any]]:
        """Profiles an ONNX model, measuring average inference time and standard deviation across multiple runs."""
        ...
    
    def generate_table_row(self, model_name, t_onnx, t_engine, model_info): # -> str:
        """Generates a table row string with model performance metrics including inference times and model details."""
        ...
    
    @staticmethod
    def generate_results_dict(model_name, t_onnx, t_engine, model_info): # -> dict[str, Any]:
        """Generates a dictionary of profiling results including model name, parameters, GFLOPs, and speed metrics."""
        ...
    
    @staticmethod
    def print_table(table_rows): # -> None:
        """Prints a formatted table of model profiling results, including speed and accuracy metrics."""
        ...
    


